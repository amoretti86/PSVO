{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on Smoothing Nonlinear Variational Objectives with SMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoniomoretti/anaconda3/envs/miniphd/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/antoniomoretti/anaconda3/envs/miniphd/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = '/Users/antoniomoretti/PycharmProjects/NormFlows/4.4.19/SMC_supreme/'\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoniomoretti/anaconda3/envs/miniphd/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/Users/antoniomoretti/anaconda3/envs/miniphd/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from runner import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the code is written in:\n",
      "\t tensorflow version: 1.12.0\n",
      "\t tensorflow_probability version: 0.5.0\n",
      "the system uses:\n",
      "\t tensorflow version: 1.12.0\n",
      "\t tensorflow_probability version: 0.5.0\n"
     ]
    }
   ],
   "source": [
    "np.warnings.filterwarnings('ignore')\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # to avoid lots of log about the device\n",
    "\n",
    "print(\"the code is written in:\")\n",
    "print(\"\\t tensorflow version: 1.12.0\")\n",
    "print(\"\\t tensorflow_probability version: 0.5.0\")\n",
    "\n",
    "print(\"the system uses:\")\n",
    "print(\"\\t tensorflow version:\", tf.__version__)\n",
    "print(\"\\t tensorflow_probability version:\", tfp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateTrainingData = False\n",
    "datadir = '/Users/antoniomoretti/PycharmProjects/NormFlows/4.4.19/data/fitzhughnagumo/'\n",
    "datadict = 'datadict'\n",
    "# Was the data pickled in Python2?\n",
    "isPython2 = True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dx = 2\n",
    "Dy = 1\n",
    "Di = 1\n",
    "poisson_emission = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_particles = 32\n",
    "batch_size = 1\n",
    "lr = 2e-4\n",
    "epoch = 300\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time, n_train and n_test will be overwritten if loading data from the file\n",
    "time = 200\n",
    "n_train = 200 * batch_size\n",
    "n_test = 40 * batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop training early if validation set does not improve\n",
    "early_stop_patience = 200\n",
    "# reduce learning rate when testing loss doesn't improve for some time\n",
    "lr_reduce_patience = 30\n",
    "# the factor to reduce lr, new_lr = old_lr * lr_reduce_factor\n",
    "lr_reduce_factor = 1 / np.sqrt(2)\n",
    "# minimum lr\n",
    "min_lr = lr / 10\n",
    "# The clipping ratio of gradient based on global L2 norm\n",
    "clip_norm = 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed-Forward Network (FFN)\n",
    "q0_layers = [64]        # q(x_1|y_1) or q(x_1|y_1:T)\n",
    "q1_layers = [64]        # q(x_t|x_{t-1})\n",
    "q2_layers = [64]        # q(x_t|y_t) or q(x_t|y_1:T)\n",
    "f_layers = [64]\n",
    "g_layers = [64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance Terms\n",
    "q0_sigma_init, q0_sigma_min = 5, 1\n",
    "q1_sigma_init, q1_sigma_min = 5, 1\n",
    "q2_sigma_init, q2_sigma_min = 5, 1\n",
    "f_sigma_init, f_sigma_min = 5, 1\n",
    "g_sigma_init, g_sigma_min = 5, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing Flow (NF)\n",
    "q1_flow_layers  = 2\n",
    "f_flow_layers   = 2\n",
    "flow_sample_num = 25\n",
    "flow_type       = \"MAF\"\n",
    "\n",
    "# bidirectional RNN\n",
    "y_smoother_Dhs = [64]\n",
    "X0_smoother_Dhs = [64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSM Parameter Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do q1 and f share the same network?\n",
    "# (Even if use_2_q == True, f and q1 can still use different networks)\n",
    "use_bootstrap = True\n",
    "\n",
    "# should q use true_X to sample? (useful for debugging)\n",
    "q_uses_true_X = False\n",
    "\n",
    "# if q uses two networks q1(x_t|x_t-1) and q2(x_t|y_t)\n",
    "# if True, q_uses_true_X will be overwritten as False\n",
    "use_2_q = True\n",
    "\n",
    "# whether use input in q and f\n",
    "use_input = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether transitions (q1 and f) use Normalizing Flow\n",
    "flow_transition = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Parameters for Network Training and Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if f and q use residual\n",
    "use_residual = False\n",
    "\n",
    "# if q, f and g networks also output covariance (sigma)\n",
    "output_cov = False\n",
    "\n",
    "# if q, f and g networks also output covariance (sigma)\n",
    "diag_cov = False\n",
    "\n",
    "# dropout rate for FFN\n",
    "dropout_rate = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Parameters for Various Inference Schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- NF flags ------------------------- #\n",
    "# whether only the shift term shall be computed\n",
    "shift_only = True\n",
    "\n",
    "# whether clip the gradients of log scale term\n",
    "log_scale_clip_gradient = True\n",
    "\n",
    "# ----------------------- TFS flags ------------------------ #\n",
    "# whether use Two Filter Smoothing\n",
    "TFS = False\n",
    "\n",
    "# whether backward filtering in TFS uses different q0\n",
    "TFS_use_diff_q0 = True\n",
    "\n",
    "# ----------------------- FFBS flags ----------------------- #\n",
    "# whether use Forward Filtering Backward Smoothing\n",
    "FFBS = False\n",
    "\n",
    "# how fast the model transfers from filtering to smoothing\n",
    "smoothing_perc_factor = 2\n",
    "\n",
    "# whether use smoothing for inference or leaning\n",
    "FFBS_to_learn = False\n",
    "\n",
    "# --------------------- smoother flags --------------------- #\n",
    "# whether smooth observations with birdectional RNNs\n",
    "smooth_obs = True\n",
    "\n",
    "# whether use a separate RNN for getting X0\n",
    "X0_use_separate_RNN = True\n",
    "\n",
    "# whether use tf.contrib.rnn.stack_bidirectional_dynamic_rnn or tf.nn.bidirectional_dynamic_rnn\n",
    "# check https://stackoverflow.com/a/50552539 for differences between them\n",
    "use_stack_rnn = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing and Data Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency to evaluate testing loss & other metrics and save results\n",
    "print_freq = 5\n",
    "\n",
    "# whether to save the followings during training\n",
    "#   hidden trajectories\n",
    "#   k-step y-hat\n",
    "\n",
    "save_trajectory = True\n",
    "save_y_hat = False\n",
    "\n",
    "# dir to save all results\n",
    "rslt_dir_name = \"Allen_wI\"\n",
    "\n",
    "# number of steps to predict y-hat and calculate R_square\n",
    "MSE_steps = 30\n",
    "\n",
    "# lattice shape [# of rows, # of columns] to draw arrows in quiver plot\n",
    "lattice_shape = [25, 25]\n",
    "\n",
    "# number of testing data used to save hidden trajectories, y-hat, gradient and etc\n",
    "# will be clipped by number of testing data\n",
    "saving_num = 30\n",
    "\n",
    "# whether to save tensorboard\n",
    "save_tensorboard = False\n",
    "\n",
    "# whether to save model\n",
    "save_model = False\n",
    "\n",
    "q0_layers = \",\".join([str(x) for x in q0_layers])\n",
    "q1_layers = \",\".join([str(x) for x in q1_layers])\n",
    "q2_layers = \",\".join([str(x) for x in q2_layers])\n",
    "f_layers = \",\".join([str(x) for x in f_layers])\n",
    "g_layers = \",\".join([str(x) for x in g_layers])\n",
    "y_smoother_Dhs = \",\".join([str(x) for x in y_smoother_Dhs])\n",
    "X0_smoother_Dhs = \",\".join([str(x) for x in X0_smoother_Dhs])\n",
    "lattice_shape = \",\".join([str(x) for x in lattice_shape])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "\n",
    "\n",
    "# --------------------- training hyperparameters --------------------- #\n",
    "flags.DEFINE_integer(\"Dx\", Dx, \"dimension of hidden states\")\n",
    "flags.DEFINE_integer(\"Dy\", Dy, \"dimension of observations\")\n",
    "flags.DEFINE_integer(\"Di\", Di, \"dimension of inputs\")\n",
    "\n",
    "flags.DEFINE_integer(\"n_particles\", n_particles, \"number of particles\")\n",
    "flags.DEFINE_integer(\"batch_size\", batch_size, \"batch_size\")\n",
    "flags.DEFINE_float(\"lr\", lr, \"learning rate\")\n",
    "flags.DEFINE_integer(\"epoch\", epoch, \"number of epoch\")\n",
    "\n",
    "flags.DEFINE_integer(\"seed\", seed, \"random seed for np.random and tf\")\n",
    "\n",
    "\n",
    "# --------------------- data set parameters --------------------- #\n",
    "\n",
    "flags.DEFINE_boolean(\"generateTrainingData\", generateTrainingData, \"True: generate data set from simulation; \"\n",
    "                                                                   \"False: read data set from the file\")\n",
    "flags.DEFINE_string(\"datadir\", datadir, \"path of the data set file\")\n",
    "flags.DEFINE_string(\"datadict\", datadict, \"name of the data set file\")\n",
    "flags.DEFINE_boolean(\"isPython2\", isPython2, \"Was the data pickled in python 2?\")\n",
    "\n",
    "\n",
    "flags.DEFINE_integer(\"time\", time, \"number of timesteps for simulated data\")\n",
    "flags.DEFINE_integer(\"n_train\", n_train, \"number of trajactories for traning set\")\n",
    "flags.DEFINE_integer(\"n_test\", n_test, \"number of trajactories for testing set\")\n",
    "\n",
    "\n",
    "# --------------------- model parameters --------------------- #\n",
    "# Feed-Forward Network (FFN) architectures\n",
    "flags.DEFINE_string(\"q0_layers\", q0_layers, \"architecture for q0 network, int seperated by comma, \"\n",
    "                                            \"for example: '50,50' \")\n",
    "flags.DEFINE_string(\"q1_layers\", q1_layers, \"architecture for q1 network, int seperated by comma, \"\n",
    "                                            \"for example: '50,50' \")\n",
    "flags.DEFINE_string(\"q2_layers\", q2_layers, \"architecture for q2 network, int seperated by comma, \"\n",
    "                                            \"for example: '50,50' \")\n",
    "flags.DEFINE_string(\"f_layers\",  f_layers,  \"architecture for f network, int seperated by comma, \"\n",
    "                                            \"for example: '50,50' \")\n",
    "flags.DEFINE_string(\"g_layers\",  g_layers,  \"architecture for g network, int seperated by comma, \"\n",
    "                                            \"for example: '50,50' \")\n",
    "\n",
    "flags.DEFINE_float(\"q0_sigma_init\", q0_sigma_init, \"initial value of q0_sigma\")\n",
    "flags.DEFINE_float(\"q1_sigma_init\", q1_sigma_init, \"initial value of q1_sigma\")\n",
    "flags.DEFINE_float(\"q2_sigma_init\", q2_sigma_init, \"initial value of q2_sigma\")\n",
    "flags.DEFINE_float(\"f_sigma_init\",  f_sigma_init,  \"initial value of f_sigma\")\n",
    "flags.DEFINE_float(\"g_sigma_init\",  g_sigma_init,  \"initial value of g_sigma\")\n",
    "\n",
    "flags.DEFINE_float(\"q0_sigma_min\", q0_sigma_min, \"minimal value of q0_sigma\")\n",
    "flags.DEFINE_float(\"q1_sigma_min\", q1_sigma_min, \"minimal value of q1_sigma\")\n",
    "flags.DEFINE_float(\"q2_sigma_min\", q2_sigma_min, \"minimal value of q2_sigma\")\n",
    "flags.DEFINE_float(\"f_sigma_min\",  f_sigma_min,  \"minimal value of f_sigma\")\n",
    "flags.DEFINE_float(\"g_sigma_min\",  g_sigma_min,  \"minimal value of g_sigma\")\n",
    "\n",
    "# Normalizing Flow\n",
    "flags.DEFINE_integer(\"q1_flow_layers\",  q1_flow_layers,  \"number of layers of q1 normalizing flow\")\n",
    "flags.DEFINE_integer(\"f_flow_layers\",   f_flow_layers,   \"number of layers of f normalizing flow\")\n",
    "flags.DEFINE_integer(\"flow_sample_num\", flow_sample_num, \"number of samples used to determine the mean of flow\")\n",
    "flags.DEFINE_string(\"flow_type\",        flow_type,       \"type of flow to use: MAF, IAF or RealNVP\")\n",
    "\n",
    "# bidirectional RNN\n",
    "flags.DEFINE_string(\"y_smoother_Dhs\", y_smoother_Dhs, \"number of units for y_smoother birdectional RNNs, \"\n",
    "                                                      \"int seperated by comma\")\n",
    "flags.DEFINE_string(\"X0_smoother_Dhs\", X0_smoother_Dhs, \"number of units for X0_smoother birdectional RNNs, \"\n",
    "                                                        \"int seperated by comma\")\n",
    "\n",
    "# --------------------- SSM flags --------------------- #\n",
    "flags.DEFINE_boolean(\"use_bootstrap\", use_bootstrap, \"whether q1 and f share the same network, \"\n",
    "                                                     \"(ATTENTION: even if use_2_q == True, \"\n",
    "                                                     \"f and q1 can still use different networks)\")\n",
    "flags.DEFINE_boolean(\"q_uses_true_X\", q_uses_true_X, \"whether q1 uses true hidden states to sample\")\n",
    "flags.DEFINE_boolean(\"use_2_q\", use_2_q, \"whether q uses two networks q1(x_t|x_t-1) and q2(x_t|y_t), \"\n",
    "                                         \"if True, q_uses_true_X will be overwritten as False\")\n",
    "flags.DEFINE_boolean(\"use_input\", use_input, \"whether use input in q and f\")\n",
    "flags.DEFINE_boolean(\"flow_transition\", flow_transition, \"whether transitions (q1 and f) use Normalizing Flow\")\n",
    "flags.DEFINE_boolean(\"poisson_emission\", poisson_emission, \"whether emission uses Poisson distribution\")\n",
    "\n",
    "# --------------------- FFN flags --------------------- #\n",
    "\n",
    "flags.DEFINE_boolean(\"use_residual\", use_residual, \"whether f and q use residual network\")\n",
    "flags.DEFINE_boolean(\"output_cov\", output_cov, \"whether q, f and g networks also output covariance (sigma)\")\n",
    "flags.DEFINE_boolean(\"diag_cov\", diag_cov, \"whether the networks only output diagonal value of cov matrix\")\n",
    "flags.DEFINE_float(\"dropout_rate\", dropout_rate, \"dropout rate for FFN\")\n",
    "\n",
    "# ----------------------- NF flags ------------------------- #\n",
    "\n",
    "flags.DEFINE_boolean(\"shift_only\", shift_only, \"whether only the shift term shall be computed\")\n",
    "flags.DEFINE_boolean(\"log_scale_clip_gradient\", log_scale_clip_gradient,\n",
    "                     \"whether clip the gradients of log scale term\")\n",
    "\n",
    "# ----------------------- TFS flags ------------------------ #\n",
    "\n",
    "flags.DEFINE_boolean(\"TFS\", TFS, \"whether use Two Filter Smoothing\")\n",
    "flags.DEFINE_boolean(\"TFS_use_diff_q0\", TFS_use_diff_q0, \"whether backward filtering in TFS uses different q0\")\n",
    "\n",
    "# ----------------------- FFBS flags ----------------------- #\n",
    "\n",
    "flags.DEFINE_boolean(\"FFBS\", FFBS, \"whether use Forward Filtering Backward Smoothing\")\n",
    "flags.DEFINE_float(\"smoothing_perc_factor\", smoothing_perc_factor,\n",
    "                   \"determine how the percentage of smoothing loss in the total loss changes with epoch num, \"\n",
    "                   \"the percentage of smoothing loss = 1 - (1 - current_epoch / total_epoch) ** smoothing_perc_factor\")\n",
    "flags.DEFINE_boolean(\"FFBS_to_learn\", FFBS_to_learn, \"whether use FFBS for leaning or inference\")\n",
    "\n",
    "# --------------------- smoother flags --------------------- #\n",
    "\n",
    "flags.DEFINE_boolean(\"smooth_obs\", smooth_obs, \"whether smooth observations with birdectional RNNs\")\n",
    "flags.DEFINE_boolean(\"X0_use_separate_RNN\", X0_use_separate_RNN, \"whether use a separate RNN for getting X0\")\n",
    "flags.DEFINE_boolean(\"use_stack_rnn\", use_stack_rnn, \"whether use tf.contrib.rnn.stack_bidirectional_dynamic_rnn \"\n",
    "                                                     \"or tf.nn.bidirectional_dynamic_rnn\")\n",
    "\n",
    "# --------------------- training flags --------------------- #\n",
    "\n",
    "flags.DEFINE_integer(\"early_stop_patience\", early_stop_patience,\n",
    "                     \"stop training early if validation set does not improve for certain epochs\")\n",
    "\n",
    "flags.DEFINE_integer(\"lr_reduce_patience\", lr_reduce_patience,\n",
    "                     \"educe learning rate when testing loss doesn't improve for some time\")\n",
    "flags.DEFINE_float(\"lr_reduce_factor\", lr_reduce_factor,\n",
    "                   \"the factor to reduce learning rate, new_lr = old_lr * lr_reduce_factor\")\n",
    "flags.DEFINE_float(\"min_lr\", min_lr, \"minimum learning rate\")\n",
    "flags.DEFINE_float(\"clip_norm\", clip_norm, \"The clipping ratio of gradient based on global L2 norm\")\n",
    "\n",
    "# --------------------- printing and data saving params --------------------- #\n",
    "\n",
    "flags.DEFINE_integer(\"print_freq\", print_freq, \"frequency to evaluate testing loss & other metrics and save results\")\n",
    "\n",
    "flags.DEFINE_boolean(\"save_trajectory\", save_trajectory, \"whether to save hidden trajectories during training\")\n",
    "flags.DEFINE_boolean(\"save_y_hat\", save_y_hat, \"whether to save k-step y-hat during training\")\n",
    "\n",
    "flags.DEFINE_string(\"rslt_dir_name\", rslt_dir_name, \"dir to save all results\")\n",
    "flags.DEFINE_integer(\"MSE_steps\", MSE_steps, \"number of steps to predict y-hat and calculate R_square\")\n",
    "\n",
    "flags.DEFINE_string(\"lattice_shape\", lattice_shape, \"lattice shape [# of rows, # of columns] \"\n",
    "                                                    \"to draw arrows in quiver plot\")\n",
    "\n",
    "flags.DEFINE_integer(\"saving_num\", saving_num, \"number of testing data used to \"\n",
    "                                               \"save hidden trajectories, y-hat, gradient and etc, \"\n",
    "                                               \"will be clipped by number of testing data\")\n",
    "\n",
    "flags.DEFINE_boolean(\"save_tensorboard\", save_tensorboard, \"whether to save tensorboard\")\n",
    "flags.DEFINE_boolean(\"save_model\", save_model, \"whether to save model\")\n",
    "\n",
    "FLAGS = flags.FLAGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished preparing dataset\n",
      "Experiment_params:\n",
      "\tDi: 1\n",
      "\tDx: 2\n",
      "\tDy: 1\n",
      "\tFFBS: False\n",
      "\tFFBS_to_learn: False\n",
      "\tMSE_steps: 30\n",
      "\tTFS: False\n",
      "\tTFS_use_diff_q0: True\n",
      "\tX0_smoother_Dhs: 64\n",
      "\tX0_use_separate_RNN: True\n",
      "\tbatch_size: 1\n",
      "\tclip_norm: 10.0\n",
      "\tdatadict: datadict\n",
      "\tdatadir: /Users/antoniomoretti/PycharmProjects/NormFlows/4.4.19/data/fitzhughnagumo/\n",
      "\tdiag_cov: False\n",
      "\tdropout_rate: 0.0\n",
      "\tearly_stop_patience: 200\n",
      "\tepoch: 300\n",
      "\tf_flow_layers: 2\n",
      "\tf_layers: 64\n",
      "\tf_sigma_init: 5.0\n",
      "\tf_sigma_min: 1.0\n",
      "\tflow_sample_num: 25\n",
      "\tflow_transition: False\n",
      "\tflow_type: MAF\n",
      "\tg_layers: 64\n",
      "\tg_sigma_init: 5.0\n",
      "\tg_sigma_min: 1.0\n",
      "\tgenerateTrainingData: False\n",
      "\tisPython2: True\n",
      "\tlattice_shape: 25,25\n",
      "\tlog_scale_clip_gradient: True\n",
      "\tlr: 0.0002\n",
      "\tlr_reduce_factor: 0.7071067811865475\n",
      "\tlr_reduce_patience: 30\n",
      "\tmin_lr: 2e-05\n",
      "\tn_particles: 32\n",
      "\tn_test: 20\n",
      "\tn_train: 80\n",
      "\toutput_cov: False\n",
      "\tpoisson_emission: False\n",
      "\tprint_freq: 5\n",
      "\tq0_layers: 64\n",
      "\tq0_sigma_init: 5.0\n",
      "\tq0_sigma_min: 1.0\n",
      "\tq1_flow_layers: 2\n",
      "\tq1_layers: 64\n",
      "\tq1_sigma_init: 5.0\n",
      "\tq1_sigma_min: 1.0\n",
      "\tq2_layers: 64\n",
      "\tq2_sigma_init: 5.0\n",
      "\tq2_sigma_min: 1.0\n",
      "\tq_uses_true_X: False\n",
      "\trslt_dir_name: Allen_wI\n",
      "\tsave_model: False\n",
      "\tsave_tensorboard: False\n",
      "\tsave_trajectory: True\n",
      "\tsave_y_hat: False\n",
      "\tsaving_num: 20\n",
      "\tseed: 0\n",
      "\tshift_only: True\n",
      "\tsmooth_obs: True\n",
      "\tsmoothing_perc_factor: 2.0\n",
      "\ttime: 200\n",
      "\tuse_2_q: True\n",
      "\tuse_bootstrap: True\n",
      "\tuse_input: False\n",
      "\tuse_residual: False\n",
      "\tuse_stack_rnn: True\n",
      "\ty_smoother_Dhs: 64\n",
      "RLT_DIR: /Users/antoniomoretti/PycharmProjects/NormFlows/4.4.19/SMC_supreme/rslts/Allen_wI/D190409_002117_np_32_t_200_bs_1_lr_0.0002_epoch_300_seed_0/\n",
      "initializing variables...\n"
     ]
    }
   ],
   "source": [
    "tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
