%%%%%%%% ICML 2019 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{mathrsfs}
\usepackage{amsmath, amssymb}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{tikz}
\usetikzlibrary{matrix}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2019} with \usepackage[nohyperref]{icml2019} above.
\usepackage{hyperref}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
\usepackage{icml2019}

% If accepted, instead use the following line for the camera-ready submission:
%\usepackage[accepted]{icml2019}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:


\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\ba}{\begin{array}}
\newcommand{\ea}{\end{array}}
\newcommand{\bea}{\begin{eqnarray}}
\newcommand{\eea}{\end{eqnarray}}
\newcommand{\balg}{\begin{align}}
\newcommand{\ealg}{\end{align}}
\newcommand{\bit}{\begin{itemize}}
\newcommand{\eit}{\end{itemize}}
\newcommand{\trm}[1]{\textrm{#1}}
\newcommand{\mbf}[1]{\mathbf{#1}}
\newcommand{\tbf}[1]{\textbf{#1}}
\newcommand{\mcl}[1]{\mathcal{#1}}
\newcommand{\mbb}[1]{\mathbb{#1}}
\newcommand{\msc}[1]{\mathscr{#1}}
\newcommand{\lrpar}{\stackrel{\leftrightarrow}{\partial}}
\newcommand{\lpar}{\stackrel{\leftarrow}{\partial}}
\newcommand{\rpar}{\stackrel{\rightarrow}{\partial}}
\newcommand{\tcr}[1]{\textcolor{red}{#1}}
\newcommand{\tcb}[1]{\textcolor{blue}{#1}}
\newcommand{\tcg}[1]{\textcolor{green}{#1}}
\newcommand{\N}{\mcl{N}}

\newcommand{\bx}{\mbf{x}}
\newcommand{\bX}{\mbf{X}}
\newcommand{\bw}{\mbf{w}}
\newcommand{\bW}{\mbf{W}}
\newcommand{\bZ}{\mbf{Z}}
\newcommand{\bP}{\mbf{P}}
\newcommand{\bz}{\mbf{z}}
\newcommand{\bY}{\mbf{Y}}
\newcommand{\bfy}{\mbf{y}}
\newcommand{\bth}{\bm{\theta}}
\newcommand{\bSigma}{\bm{\Sigma}}
\newcommand{\bLambda}{\bm{\Lambda}}
\newcommand{\bmu}{\bm{\mu}}
\newcommand{\pvp}{\phi,\varphi}
\newcommand{\vph}{\varphi}
\newcommand{\bR}{\mbf{R}}
\newcommand{\bM}{\mbf{M}}
\newcommand{\bS}{\mbf{S}}
\newcommand{\bC}{\mbf{C}}
\newcommand{\nn}{\nonumber}

\newcommand{\vtw}{\vspace{.2cm}}
\newcommand{\vth}{\vspace{.3cm}}
\newcommand{\vsx}{\vspace{.6cm}}
\newcommand{\nwp}[1]{\vth \tbf{{#1}.}}

\newcommand{\tr}[1]{\trm{Tr}\left[ {#1} \right]}



\icmltitlerunning{Submission and Formatting Instructions for ICML 2019}

\begin{document}

\twocolumn[
\icmltitle{Smoothing Variational Objectives with Sequential Monte Carlo\\ for Nonlinear Dynamics}% \\
           %International Conference on Machine Learning (ICML 2019)}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2019
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Aeiau Zzzz}{equal,to}
\icmlauthor{Bauiu C.~Yyyy}{equal,to,goo}
\icmlauthor{Cieua Vvvvv}{goo}
\icmlauthor{Iaesut Saoeu}{ed}
\icmlauthor{Fiuea Rrrr}{to}
\icmlauthor{Tateu H.~Yasehe}{ed,to,goo}
\icmlauthor{Aaoeu Iasoh}{goo}
\icmlauthor{Buiui Eueu}{ed}
\icmlauthor{Aeuia Zzzz}{ed}
\icmlauthor{Bieea C.~Yyyy}{to,goo}
\icmlauthor{Teoau Xxxx}{ed}
\icmlauthor{Eee Pppp}{ed}
\end{icmlauthorlist}

\icmlaffiliation{to}{Department of Computer Science, Columbia University, New York, NY}
\icmlaffiliation{goo}{Googol ShallowMind, New London, Michigan, USA}
\icmlaffiliation{ed}{School of Computation, University of Edenborrow, Edenborrow, United Kingdom}

\icmlcorrespondingauthor{Cieua Vvvvv}{c.vvvvv@googol.com}
\icmlcorrespondingauthor{Eee Pppp}{ep@eden.co.uk}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
%This document provides a basic paper template and submission guidelines.
%Abstracts must be a single paragraph, ideally between 4--6 sentences long.
%Gross violations will trigger corrections at the camera-ready phase.
Conductance based models of excitable cells are widely used in computational neuroscience to characterize the spiking activity of individual neurons. Recovering the multidimensional nonlinear dynamics that govern a cell from a single observation is a challenging problem motivating the development of novel techniques in time series analysis. Sequential Monte Carlo methods have been used to construct objective functions for variational inference on time series to perform simultaneous model inference and learning. We develop smoothed variational objectives analogous to forward-backwards message passing. We demonstrate that the use of information from the full time ordered sequence of observations improves both the state estimation and the dynamics learned. Experiments show that this method compares favorably against state of the art methods for variational inference in nonlinear dynamical systems. \textbf{TL;DR summary of paper}
\end{abstract}

\section{Introduction}
\label{submission}
\textbf{motivate the statistical problem with neuroscience question. introduce the method and outline the paper.}
Conductance based models of excitable cells are widely used in computational neuroscience to characterize the spiking activity of individual neurons. Recovering the multidimensional nonlinear dynamics that govern a cell from a single observation is a challenging problem motivating the development of novel techniques in time series analysis. Recently Sequential Monte Carlo methods have been used to construct objective functions for variational inference on time series to perform simultaneous model inference and learning. We develop smoothed variational objectives analogous to forward-backwards message passing. We demonstrate that the use of information from the full time ordered sequence of observations improves both the state estimation and the dynamics learned. Experiments show that this method compares favorably against state of the art methods for variational inference in nonlinear dynamical systems.

\textbf{talk about dimensionality expansion, dimensionality reduction, prediction.}

\section{Related Work}
Discuss SMC based methods including AESMC, VSMC, FIVO. 

Contrast with pure VI methods including VRNN, DKF, LFADS, GfLDS, VIND. 


\section{Theory}
\subsection{Sequential Monte Carlo}
Give a brief review of SMC and VI. Why is this approach promising as opposed to pure VI?

SMC methods factorize an ordered sequence of observations $\bX \equiv \{\bx_1,\dots\bx_T\}$, $\bx_t\in\mbb{R}^{d_X}$ governed by an ordered a sequence of latent variables $\bZ\equiv\{\bz_1,\dots\bz_T\}$, $\bz_T\in \mbb{R}^{d_Z}$ that evolve according to stochastic dynamics. The target distribution $\{p_{\theta}(\bz_t|\bx_t)\}_{t=1}^{T}$ is assumed intractable due to 

SMC factorizes the target distribution $\{p_{\theta}(\bz_t|\bx_t)\}_{t=1}^{T}$ into a sequence of distributions of increasing spaces. 


\subsection{Auto-Encoding Sequential Monte Carlo}
Recap main idea from AESMC and FIVO. 
\be
\log p(\bX) = \log \int p(\bX, \bZ) d\bZ = \log \frac{p(\bX, \bZ)}{p(\bZ|\bX)} \,. \label{ll}
\ee


\be
\log p(\bX) \geq \msc{L}_{\trm{ELBO}}(\bX) = \underset{q}{\mbb{E}}[\log p(\bX, \bZ)] - \underset{q}{\mbb{E}} [\log q(\bZ|\bX)] \label{ELBO} \,.
\ee


\be
\hat{\mathcal{Z}}_{SMC} \equiv \prod\limits_{t=1}^{T}\Big[\frac{1}{N}\sum\limits_{n=1}^{N}w_t^{(n)} \Big] 
\ee

\subsection{Smoothing Variational Objectives}
Emphasize novelty of the proposed model, novelty of the experiments and the results. Discuss the implementation details. 

\textbf{The big question to answer is, how is this different from AESMC or FIVO in terms of theory? what is unique with respect to the applications and results?} 

nonlinear time invariant function learned on a smoothed SMC objective.


\section{Results}
Define quantitative evaluation metric. Motivate the use of k-step $MSE_k$ and k-step $R^2_k$.
\be
\trm{MSE}_k =  \sum_{t=0}^{T-k} \left( \bx_{t+k} - \hat{\bx}_{t+k} \right)^2 \,,\quad R^2_k = 1 - \frac{k\trm{MSE}}{\sum_{t=0}^{T-k} \left( \bx_{t+k} - \bar{\bx} \right)^2}
\ee

\subsection{Fitzhugh Nagumo}

\begin{align}
\dot V &= f(V) - W + I_{ext} \,, \nn\\
\dot W &= a(bV - cW)
\end{align}

\begin{figure*}
\includegraphics[width=\columnwidth]{}
\caption{Summary of the Fitzhugh Nagumo results: (left) latent dynamics and paths for the original system (center) inferred 2D dynamics and paths from a noisy 1D observation (right) $R^2_k$ for various models.}
\end{figure*}


\subsection{Lorenz Attractor}
\begin{align}
  \dot{z}_1 & = \sigma(z_2-z_1) \,, \nn \\
  \dot{z}_2 & = z_1(\rho - z_3) - z_2 \,, \\
  \dot{z}_3 & = z_1z_2 - \beta z_3\,. \nn
\end{align}
\begin{figure*}
\includegraphics[width=\columnwidth]{}
\caption{Summary of the Lorenz results: (left) latent paths for the original system (center) inferred paths from a noisy 10D observation (right) $R^2_k$ for various models}
\end{figure*}

\subsection{Single Cell Recordings}

\begin{figure*}
\includegraphics[width=\columnwidth]{}
\caption{}
\end{figure*}

\section{Discussion}


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
\nocite{*}

\bibliography{vismc}
\bibliographystyle{icml2019}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DELETE THIS PART. DO NOT PLACE CONTENT AFTER THE REFERENCES!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019. Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
